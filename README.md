A neural network a day for a long time so as to train un maximum and actually learn by doing.

## MLFrameworks used

#### TORCH

[MNIST dumb autoencoder](./MNIST_dumb_Autoencoder/day1.ipynb)

#### KERAS

[MNIST on CNN](./MNIST_with_CNN/day2.ipynb)

#### JAX

[MNIST with JAX](./MNIST_JAX/day3.ipynb)
[MNIST with JAX v2](./MNIST_JAX_2nd_attempt/day4.ipynb)
[ResNetSpeechEncoder JAX](./ResNetSpeechEncoder_with_JAX/)
[HiFiGaN JAX](./HiFiGAN_with_JAX/)

## ML Trackers used

#### TENSORBOARD

[MNIST on CNN](MNIST_with_CNN/day2.ipynb)

## Datasets used

#### MNIST

[MNIST dumb autoencoder](./MNIST_dumb_Autoencoder/day1.ipynb), [MNIST on CNN](MNIST_with_CNN/day2.ipynb), [MNIST with JAX](./MNIST_JAX/day3.ipynb), 
[MNIST with JAX v2](./MNIST_JAX_2nd_attempt/day4.ipynb)


## Architectures trained

#### Autoencoder

[MNIST dumb autoencoder](./MNIST_dumb_Autoencoder/day1.ipynb)

#### CNN

[MNIST on CNN](MNIST_with_CNN/day2.ipynb)

#### ResNetSpeechEncoder

[ResNetSpeechEncoder JAX](./ResNetSpeechEncoder_with_JAX/)

#### HiFiGAN

[HiFiGaN JAX](./HiFiGAN_with_JAX/)

## Unfinished

[MNIST with Triton](./MNIST_Triton_Accelerated/day5.ipynb)