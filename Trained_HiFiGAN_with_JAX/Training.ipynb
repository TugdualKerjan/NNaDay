{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the Generator and discriminators to thus train on the LJSpeech dataset. The dataset consists of around 13,000 samples reading from 7 non-fiction books. They vary from 1 - 10 seconds and total around 24h.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import jax\n",
    "import os\n",
    "import librosa\n",
    "import optax\n",
    "import wandb\n",
    "import equinox as eqx\n",
    "\n",
    "from Generator import Generator\n",
    "from Discriminators import MultiPeriodDiscriminator, MultiScaleDiscriminator, feature_loss, generator_loss, discriminator_loss\n",
    "\n",
    "def create_parser():\n",
    "    parser = argparse.ArgumentParser(description=\"Arguments for training HiFiGaN\")\n",
    "\n",
    "    parser.add_argument(\"--dataset_path\", \"Path to the dataset to use (LJSpeech)\")\n",
    "\n",
    "    parser.add_argument(\"--learning_rate\", \"Learning rate during training\")\n",
    "\n",
    "    parser.add_argument(\"--output_path\", \"Path to store model weights\")\n",
    "\n",
    "    return parser\n",
    "\n",
    "def save_model(model, path):\n",
    "    eqx.tree_serialise_leaves(path, model)\n",
    "\n",
    "def get_dataset(dataset_path):\n",
    "    mel_dir = os.path.join(dataset_path, 'mel_spectrograms')\n",
    "    wav_dir = os.path.join(dataset_path, 'processed_wavs')\n",
    "\n",
    "    mels = []\n",
    "    wavs = []\n",
    "    for filename in os.listdir(mel_dir):\n",
    "        np_data = jax.numpy.load(os.path.join(mel_dir, filename), allow_pickle=True)\n",
    "        # print(np_data.shape)\n",
    "        mels.append(np_data[:,:-1])\n",
    "\n",
    "    for filename in os.listdir(wav_dir):\n",
    "        wav_data, _ = librosa.load(os.path.join(wav_dir, filename))\n",
    "        # print(wav_data.shape)\n",
    "\n",
    "        wavs.append(jax.numpy.array(wav_data))\n",
    "\n",
    "    return jax.numpy.array(mels), jax.numpy.array(wavs)\n",
    "\n",
    "\n",
    "def train_hifigan(dataset_path, output_path, learning_rate=1e-4, batch_size=1, epochs=1, seed=69):\n",
    "    run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"HiFiGaN JAX\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"PRNG_SEED\": seed,\n",
    "    },\n",
    ")\n",
    "\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "    generator = Generator(channels_in=80, channels_out=1, key=key1)\n",
    "    scale_disc = MultiScaleDiscriminator(key=key2)\n",
    "    period_disc = MultiPeriodDiscriminator(key=key3)\n",
    "\n",
    "    dataset_mels, dataset_wavs = get_dataset(\"dataset\")\n",
    "\n",
    "\n",
    "    @eqx.filter_value_and_grad\n",
    "    def calculate_loss(model, x, y):\n",
    "        result = jax.vmap(model)(x)\n",
    "        return jax.numpy.mean(jax.numpy.abs(result - y)) # L1 loss\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(model, x, y, optim_state):\n",
    "        loss, grads = calculate_loss(model, x, y)\n",
    "        updates, optim_state = optim.update(grads, optim_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return loss, model, optim_state\n",
    "\n",
    "    optim = optax.adam(learning_rate)\n",
    "    optim_state = optim.init(generator)\n",
    "    # print(dataset)\n",
    "    for epoch in range(epochs):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        perm = jax.random.permutation(subkey, len(dataset_mels))\n",
    "        \n",
    "        for batch_start in range(0, len(dataset_mels), batch_size):\n",
    "            batch_indices = perm[batch_start: batch_start + batch_size]\n",
    "            x = dataset_mels.take(batch_indices, axis=0)\n",
    "            y = dataset_wavs.take(batch_indices, axis=0)\n",
    "            \n",
    "            # Display batch indices and data\n",
    "            loss, generator, optim_state = make_step(generator, x, y, optim_state)\n",
    "            # print(grads)        loss = loss.item()\n",
    "            wandb.log({\"loss\": loss})\n",
    "            # print(batch_data.shape)\n",
    "\n",
    "            # print(res.shape)\n",
    "\n",
    "        save_model(generator, os.path.join(output_path, f\"generator_epoch_{epoch}.eqx\"))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = create_parser()\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     train_hifigan(dataset_path=args.dataset_path, output_path=args.output_path, learning_rate=args.learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtugdual-kerjan\u001b[0m (\u001b[33mtugdualk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tugdual/Documents/Kera/JAXTTS/NNaDay/Trained_HiFiGAN_with_JAX/wandb/run-20241026_121145-h8hljpe4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tugdualk/HiFiGaN%20JAX/runs/h8hljpe4' target=\"_blank\">lyric-sun-1</a></strong> to <a href='https://wandb.ai/tugdualk/HiFiGaN%20JAX' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tugdualk/HiFiGaN%20JAX' target=\"_blank\">https://wandb.ai/tugdualk/HiFiGaN%20JAX</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tugdualk/HiFiGaN%20JAX/runs/h8hljpe4' target=\"_blank\">https://wandb.ai/tugdualk/HiFiGaN%20JAX/runs/h8hljpe4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_hifigan(dataset_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 92\u001b[0m, in \u001b[0;36mtrain_hifigan\u001b[0;34m(dataset_path, output_path, learning_rate, batch_size, epochs, seed)\u001b[0m\n\u001b[1;32m     89\u001b[0m y \u001b[38;5;241m=\u001b[39m dataset_wavs\u001b[38;5;241m.\u001b[39mtake(batch_indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Display batch indices and data\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m loss, generator, optim_state \u001b[38;5;241m=\u001b[39m make_step(generator, x, y, optim_state)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# print(grads)        loss = loss.item()\u001b[39;00m\n\u001b[1;32m     94\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss})\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jaxtts/lib/python3.11/site-packages/equinox/_jit.py:248\u001b[0m, in \u001b[0;36m_JitWrapper._call\u001b[0;34m(self, is_lower, args, kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m         marker, _, _ \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached(\n\u001b[1;32m    245\u001b[0m             dynamic_donate, dynamic_nodonate, static\n\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jitting:\n\u001b[0;32m--> 248\u001b[0m         marker\u001b[38;5;241m.\u001b[39mblock_until_ready()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JaxRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Catch Equinox's runtime errors, and re-raise them with actually useful\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# information. (By default XlaRuntimeError produces a lot of terrifying\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# but useless information.)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m         last_msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m last_stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# callback necessarily executed in the same interpreter as we are in\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# here?\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_hifigan(dataset_path=\"dataset\", output_path=\"checkpoint\", learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxtts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
