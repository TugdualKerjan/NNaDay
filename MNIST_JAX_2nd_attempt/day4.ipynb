{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 14:02:22.799840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-26 14:02:23.013983: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-26 14:02:23.076580: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-26 14:02:25.269812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tensorflow\n",
    "\n",
    "from jax import grad, random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import flax.linen as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    features = Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, num_features):\n",
    "        x = nn.Conv(features=32, kernel_size=(3,3), strides=(2,2))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.max_pool(x, window_shape=(2,2))\n",
    "        # x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Conv(features=128, kernel_size=(3,3), strides=(2,2))(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2))\n",
    "        x = nn.Dropout(0.2, deterministic=True)(x)\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(128)(x)\n",
    "\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(num_features)(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "number_of_train_samples = x_train.shape[0]\n",
    "\n",
    "batch_size = 128\n",
    "number_of_batches, extra = divmod(number_of_train_samples, batch_size)\n",
    "number_of_iterations = number_of_batches\n",
    "variables = model.init(random.PRNGKey(0), jnp.ones([1, 28, 28, 1]), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Conv_0', 'Conv_1', 'Dense_0', 'Dense_1'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(variables)\n",
    "variables[\"params\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, x, y):\n",
    "    logits = model.apply({\"params\": params}, x, num_features=10)\n",
    "    loss =  -jnp.mean(jnp.sum(nn.log_softmax(logits) * jax.nn.one_hot(y, 10), axis=-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(61.576347, dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits = model.apply({\"params\": variables[\"params\"]}, x_train[0], num_features=10)\n",
    "# print(logits)\n",
    "untrained_accuracy = loss(variables[\"params\"], jnp.array(x_test), jnp.array(y_test))\n",
    "untrained_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions: [1 3 3 1 6 3 6 2 6]\n"
     ]
    }
   ],
   "source": [
    "def predict(params, x):\n",
    "    return jnp.argmax(model.apply({'params': params}, x, 10), axis=-1)\n",
    "\n",
    "# Predict on first few test images\n",
    "untrained_predictions = predict(variables[\"params\"], jnp.array(x_test[:9]))\n",
    "print(\"Untrained model predictions:\", untrained_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your loss function is already defined\n",
    "\n",
    "def train_step(params: dict, x: jnp.ndarray, y: jnp.ndarray, lr: float = 1e-4) -> dict:\n",
    "    # Compute gradients\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    \n",
    "    # # Debug prints for types\n",
    "    # print(\"Type of params:\", type(params))  # Should be a dict\n",
    "    # print(\"Type of grads:\", type(grads))  # Should be a dict similar to params\n",
    "    # for layer in params:\n",
    "        # print(f\"Type of params[{layer}]:\", type(params[layer]))\n",
    "        # print(f\"Type of grads[{layer}]:\", type(grads[layer]))\n",
    "    # Update parameters\n",
    "    updated_params = {}\n",
    "    for layer in params:\n",
    "        updated_layer = {}\n",
    "        for param in params[layer]:\n",
    "            # print(f\"Type of params[{layer}][{param}]:\", type(params[layer][param]))\n",
    "            # print(f\"Type of grads[{layer}][{param}]:\", type(grads[layer][param]))\n",
    "            updated_layer[param] = params[layer][param] - lr * grads[layer][param]\n",
    "        updated_params[layer] = updated_layer\n",
    "    \n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 0.4874567985534668\n",
      "Epoch: 0, Batch: 1, Loss: 0.4586877226829529\n",
      "Epoch: 0, Batch: 2, Loss: 0.6515821218490601\n",
      "Epoch: 0, Batch: 3, Loss: 0.4736673831939697\n",
      "Epoch: 0, Batch: 4, Loss: 0.5322296619415283\n",
      "Epoch: 0, Batch: 5, Loss: 0.34456968307495117\n",
      "Epoch: 0, Batch: 6, Loss: 0.6651368141174316\n",
      "Epoch: 0, Batch: 7, Loss: 0.504629909992218\n",
      "Epoch: 0, Batch: 8, Loss: 0.4719313383102417\n",
      "Epoch: 0, Batch: 9, Loss: 0.4522278606891632\n",
      "Epoch: 0, Batch: 10, Loss: 0.6014803647994995\n",
      "Epoch: 0, Batch: 11, Loss: 0.6190075278282166\n",
      "Epoch: 0, Batch: 12, Loss: 0.5695731043815613\n",
      "Epoch: 0, Batch: 13, Loss: 0.5421462655067444\n",
      "Epoch: 0, Batch: 14, Loss: 0.5564326643943787\n",
      "Epoch: 0, Batch: 15, Loss: 0.4878612458705902\n",
      "Epoch: 0, Batch: 16, Loss: 0.6377912759780884\n",
      "Epoch: 0, Batch: 17, Loss: 0.39376533031463623\n",
      "Epoch: 0, Batch: 18, Loss: 0.38760364055633545\n",
      "Epoch: 0, Batch: 19, Loss: 0.5064979791641235\n",
      "Epoch: 0, Batch: 20, Loss: 0.7101674675941467\n",
      "Epoch: 0, Batch: 21, Loss: 0.4420700967311859\n",
      "Epoch: 0, Batch: 22, Loss: 0.39864617586135864\n",
      "Epoch: 0, Batch: 23, Loss: 0.5300636887550354\n",
      "Epoch: 0, Batch: 24, Loss: 0.4427289366722107\n",
      "Epoch: 0, Batch: 25, Loss: 0.49694252014160156\n",
      "Epoch: 0, Batch: 26, Loss: 0.38992956280708313\n",
      "Epoch: 0, Batch: 27, Loss: 0.4272405505180359\n",
      "Epoch: 0, Batch: 28, Loss: 0.4394015073776245\n",
      "Epoch: 0, Batch: 29, Loss: 0.7883380651473999\n",
      "Epoch: 0, Batch: 30, Loss: 0.5022910833358765\n",
      "Epoch: 0, Batch: 31, Loss: 0.6227453947067261\n",
      "Epoch: 0, Batch: 32, Loss: 0.42634451389312744\n",
      "Epoch: 0, Batch: 33, Loss: 0.3661009669303894\n",
      "Epoch: 0, Batch: 34, Loss: 0.5079877972602844\n",
      "Epoch: 0, Batch: 35, Loss: 0.4154822826385498\n",
      "Epoch: 0, Batch: 36, Loss: 0.7056165933609009\n",
      "Epoch: 0, Batch: 37, Loss: 0.3832473158836365\n",
      "Epoch: 0, Batch: 38, Loss: 0.5430669188499451\n",
      "Epoch: 0, Batch: 39, Loss: 0.46051663160324097\n",
      "Epoch: 0, Batch: 40, Loss: 0.511101484298706\n",
      "Epoch: 0, Batch: 41, Loss: 0.6208664178848267\n",
      "Epoch: 0, Batch: 42, Loss: 0.31301844120025635\n",
      "Epoch: 0, Batch: 43, Loss: 0.5604584813117981\n",
      "Epoch: 0, Batch: 44, Loss: 0.5078296661376953\n",
      "Epoch: 0, Batch: 45, Loss: 0.49203240871429443\n",
      "Epoch: 0, Batch: 46, Loss: 0.49428319931030273\n",
      "Epoch: 0, Batch: 47, Loss: 0.5999196767807007\n",
      "Epoch: 0, Batch: 48, Loss: 0.4038776755332947\n",
      "Epoch: 0, Batch: 49, Loss: 0.40052318572998047\n",
      "Epoch: 0, Batch: 50, Loss: 0.32062315940856934\n",
      "Epoch: 0, Batch: 51, Loss: 0.4297161102294922\n",
      "Epoch: 0, Batch: 52, Loss: 0.384072482585907\n",
      "Epoch: 0, Batch: 53, Loss: 0.40549391508102417\n",
      "Epoch: 0, Batch: 54, Loss: 0.4980722665786743\n",
      "Epoch: 0, Batch: 55, Loss: 0.8194210529327393\n",
      "Epoch: 0, Batch: 56, Loss: 0.49948281049728394\n",
      "Epoch: 0, Batch: 57, Loss: 0.5632649660110474\n",
      "Epoch: 0, Batch: 58, Loss: 0.5949596762657166\n",
      "Epoch: 0, Batch: 59, Loss: 0.4776594638824463\n",
      "Epoch: 0, Batch: 60, Loss: 0.7247592806816101\n",
      "Epoch: 0, Batch: 61, Loss: 0.5173338651657104\n",
      "Epoch: 0, Batch: 62, Loss: 0.5175685286521912\n",
      "Epoch: 0, Batch: 63, Loss: 0.5014185905456543\n",
      "Epoch: 0, Batch: 64, Loss: 0.40469682216644287\n",
      "Epoch: 0, Batch: 65, Loss: 0.47024863958358765\n",
      "Epoch: 0, Batch: 66, Loss: 0.4142203629016876\n",
      "Epoch: 0, Batch: 67, Loss: 0.6579657793045044\n",
      "Epoch: 0, Batch: 68, Loss: 0.6291755437850952\n",
      "Epoch: 0, Batch: 69, Loss: 0.37877699732780457\n",
      "Epoch: 0, Batch: 70, Loss: 0.3442169427871704\n",
      "Epoch: 0, Batch: 71, Loss: 0.31142300367355347\n",
      "Epoch: 0, Batch: 72, Loss: 0.4963674545288086\n",
      "Epoch: 0, Batch: 73, Loss: 0.7692532539367676\n",
      "Epoch: 0, Batch: 74, Loss: 0.47425711154937744\n",
      "Epoch: 0, Batch: 75, Loss: 0.48999419808387756\n",
      "Epoch: 0, Batch: 76, Loss: 0.5170316100120544\n",
      "Epoch: 0, Batch: 77, Loss: 0.7057740688323975\n",
      "Epoch: 0, Batch: 78, Loss: 0.4364900290966034\n",
      "Epoch: 0, Batch: 79, Loss: 0.3786349594593048\n",
      "Epoch: 0, Batch: 80, Loss: 0.4543924331665039\n",
      "Epoch: 0, Batch: 81, Loss: 0.4764067530632019\n",
      "Epoch: 0, Batch: 82, Loss: 0.5857888460159302\n",
      "Epoch: 0, Batch: 83, Loss: 0.36507511138916016\n",
      "Epoch: 0, Batch: 84, Loss: 0.6147832274436951\n",
      "Epoch: 0, Batch: 85, Loss: 0.35382765531539917\n",
      "Epoch: 0, Batch: 86, Loss: 0.6028401851654053\n",
      "Epoch: 0, Batch: 87, Loss: 0.5919780731201172\n",
      "Epoch: 0, Batch: 88, Loss: 0.5621422529220581\n",
      "Epoch: 0, Batch: 89, Loss: 0.5290913581848145\n",
      "Epoch: 0, Batch: 90, Loss: 0.6742031574249268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m idxs \u001b[38;5;241m=\u001b[39m random_perm[i\u001b[38;5;241m*\u001b[39mbatch_size: (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(idxs)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# print(idxs)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print(x_train[idxs].shape)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43midxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m loss(params, x_train[idxs], y_train[idxs])\n\u001b[1;32m     11\u001b[0m jax\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Batch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, epoch, i, current_loss)\n",
      "Cell \u001b[0;32mIn[81], line 5\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(params, x, y, lr)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(params: \u001b[38;5;28mdict\u001b[39m, x: jnp\u001b[38;5;241m.\u001b[39mndarray, y: jnp\u001b[38;5;241m.\u001b[39mndarray, lr: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# # Debug prints for types\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(\"Type of params:\", type(params))  # Should be a dict\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# print(\"Type of grads:\", type(grads))  # Should be a dict similar to params\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# print(f\"Type of grads[{layer}]:\", type(grads[layer]))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     updated_params \u001b[38;5;241m=\u001b[39m {}\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/api.py:633\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 633\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/api.py:703\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 703\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    706\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/api.py:2197\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2196\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2197\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2198\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:142\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(traceable, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 142\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:131\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    130\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 131\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/profiler.py:333\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    332\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:778\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[38;5;241m=\u001b[39mcurrent_name_stack) \u001b[38;5;28;01mas\u001b[39;00m main:\n\u001b[1;32m    777\u001b[0m   fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[0;32m--> 778\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    780\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun, env\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/linear_util.py:193\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m, in \u001b[0;36mloss\u001b[0;34m(params, x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(params, x, y):\n\u001b[0;32m----> 2\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m-\u001b[39mjnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39msum(nn\u001b[38;5;241m.\u001b[39mlog_softmax(logits) \u001b[38;5;241m*\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(y, \u001b[38;5;241m10\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:2230\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m   method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m\n\u001b[1;32m   2229\u001b[0m method \u001b[38;5;241m=\u001b[39m _get_unbound_fn(method)\n\u001b[0;32m-> 2230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcapture_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_intermediates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrngs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/core/scope.py:1108\u001b[0m, in \u001b[0;36mapply.<locals>.wrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1103\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mApplyScopeInvalidVariablesStructureError(variables)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m bind(\n\u001b[1;32m   1106\u001b[0m   variables, rngs\u001b[38;5;241m=\u001b[39mrngs, mutable\u001b[38;5;241m=\u001b[39mmutable, flags\u001b[38;5;241m=\u001b[39mflags\n\u001b[1;32m   1107\u001b[0m )\u001b[38;5;241m.\u001b[39mtemporary() \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m-> 1108\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mutable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m y, root\u001b[38;5;241m.\u001b[39mmutable_variables()\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:3010\u001b[0m, in \u001b[0;36mapply.<locals>.scope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3008\u001b[0m _context\u001b[38;5;241m.\u001b[39mcapture_stack\u001b[38;5;241m.\u001b[39mappend(capture_intermediates)\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3010\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_deep_clone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3011\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3012\u001b[0m   _context\u001b[38;5;241m.\u001b[39mcapture_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:694\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 694\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:1211\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1210\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1211\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mCNN.__call__\u001b[0;34m(self, x, num_features)\u001b[0m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mmax_pool(x, window_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# x = x.reshape((x.shape[0], -1))  # flatten\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mavg_pool(x, window_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(x)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:694\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 694\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:1211\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1210\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1211\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/linear.py:631\u001b[0m, in \u001b[0;36m_Conv.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m kernel_shape:\n\u001b[1;32m    626\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask needs to have the same shape as weights. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShapes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    629\u001b[0m   )\n\u001b[0;32m--> 631\u001b[0m kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dtype\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m   kernel \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/linen/module.py:1867\u001b[0m, in \u001b[0;36mModule.param\u001b[0;34m(self, name, init_fn, unbox, *init_args, **init_kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNameInUseError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m'\u001b[39m, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1867\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mchildren[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/flax/core/scope.py:979\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args, **init_kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m   value \u001b[38;5;241m=\u001b[39m meta\u001b[38;5;241m.\u001b[39munbox(value)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# Validate that the shape of the init_fn output is the same as the shape\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;66;03m# of the existing parameter. This is to make sure that the hparams set up\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;66;03m# in a Flax Module match the shapes coming in during apply, and if not,\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# catch it with an error message.\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# NOTE: We could consider moving this to `self.`\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m abs_value \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m abs_value_flat \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_leaves(abs_value)\n\u001b[1;32m    983\u001b[0m value_flat \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_leaves(value)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/api.py:2830\u001b[0m, in \u001b[0;36meval_shape\u001b[0;34m(fun, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mhash\u001b[39m(fun)\n\u001b[1;32m   2829\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m: fun \u001b[38;5;241m=\u001b[39m partial(fun)\n\u001b[0;32m-> 2830\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval_shape(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/api.py:283\u001b[0m, in \u001b[0;36mjit\u001b[0;34m(fun, in_shardings, out_shardings, static_argnums, static_argnames, donate_argnums, donate_argnames, keep_unused, device, backend, inline, abstracted_axes)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit\u001b[39m(\n\u001b[1;32m    145\u001b[0m   fun: Callable,\n\u001b[1;32m    146\u001b[0m   in_shardings\u001b[38;5;241m=\u001b[39msharding_impls\u001b[38;5;241m.\u001b[39mUNSPECIFIED,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m   abstracted_axes: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    157\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pjit\u001b[38;5;241m.\u001b[39mJitWrapped:\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets up ``fun`` for just-in-time compilation with XLA.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    Array([   0,    1,  256, 6561], dtype=int32)\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_jit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstracted_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_resource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/pjit.py:526\u001b[0m, in \u001b[0;36mmake_jit\u001b[0;34m(fun, in_shardings, out_shardings, donate_argnums, donate_argnames, static_argnums, static_argnames, device, backend, abstracted_axes, keep_unused, inline, use_resource_env)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_jit\u001b[39m(fun: Callable, in_shardings: Any, out_shardings: Any,\n\u001b[1;32m    518\u001b[0m              donate_argnums: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Sequence[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    519\u001b[0m              donate_argnames: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Iterable[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m              abstracted_axes: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, keep_unused: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    524\u001b[0m              inline: \u001b[38;5;28mbool\u001b[39m, use_resource_env: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    525\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"jit() and pjit() are thin wrappers around this function.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m   jit_info \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_jit_arguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdonate_argnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_argnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_argnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstracted_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_resource_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _make_jit_wrapper(fun, jit_info)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/pjit.py:432\u001b[0m, in \u001b[0;36m_parse_jit_arguments\u001b[0;34m(fun, in_shardings, out_shardings, donate_argnums, donate_argnames, static_argnums, static_argnames, device, backend, abstracted_axes, keep_unused, inline, use_resource_env)\u001b[0m\n\u001b[1;32m    429\u001b[0m out_layouts, out_shardings \u001b[38;5;241m=\u001b[39m _split_layout_and_sharding(out_shardings)\n\u001b[1;32m    431\u001b[0m in_shardings \u001b[38;5;241m=\u001b[39m prepare_axis_resources(in_shardings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_shardings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 432\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_axis_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mout_shardings\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m user_specified_in_shardings \u001b[38;5;241m=\u001b[39m (in_shardings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    435\u001b[0m                                \u001b[38;5;129;01mnot\u001b[39;00m is_unspecified(in_shardings))\n\u001b[1;32m    437\u001b[0m in_shardings_leaves, in_shardings_treedef \u001b[38;5;241m=\u001b[39m none_lr\u001b[38;5;241m.\u001b[39mflatten(in_shardings)\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/sharding_impls.py:1118\u001b[0m, in \u001b[0;36mprepare_axis_resources\u001b[0;34m(axis_resources, arg_name, allow_unconstrained_dims)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     new_entries\u001b[38;5;241m.\u001b[39mappend(ParsedPartitionSpec\u001b[38;5;241m.\u001b[39mfrom_user_input(\n\u001b[1;32m   1115\u001b[0m         entry, what, allow_unconstrained_dims\u001b[38;5;241m=\u001b[39mallow_unconstrained_dims))\n\u001b[1;32m   1117\u001b[0m _check_unique_resources(new_entries, arg_name)\n\u001b[0;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_unflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_entries\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aday/MNIST_JAX_2nd_attempt/test/lib/python3.10/site-packages/jax/_src/tree_util.py:82\u001b[0m, in \u001b[0;36mtree_unflatten\u001b[0;34m(treedef, leaves)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :func:`jax.tree.flatten`.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_registry\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;129m@export\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(treedef: PyTreeDef, leaves: Iterable[Leaf]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :func:`jax.tree.unflatten`.\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(leaves)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# params = variables[\"params\"]\n",
    "for epoch in range(10):\n",
    "    random_perm = np.random.permutation(x_train.shape[0])\n",
    "    for i in range(0, number_of_iterations):\n",
    "        idxs = random_perm[i*batch_size: (i+1) * batch_size]\n",
    "        # print(idxs)\n",
    "        # print(idxs)\n",
    "        # print(x_train[idxs].shape)\n",
    "        params = train_step(params, x_train[idxs], y_train[idxs])\n",
    "        current_loss = loss(params, x_train[idxs], y_train[idxs])\n",
    "        jax.debug.print(\"Epoch: {}, Batch: {}, Loss: {}\", epoch, i, current_loss)\n",
    "        # print(x_train[idxs].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1751/4090668910.py:7: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
      "  z=jax.xla_computation(dlfn)(params, np.expand_dims(x_train[0],0), y_train[0])\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "def dlfn(params, x, y ):\n",
    "    return grad(loss)(params, x, y)\n",
    "\n",
    "print(x_train[0].shape)\n",
    "\n",
    "z=jax.xla_computation(dlfn)(params, np.expand_dims(x_train[0],0), y_train[0])\n",
    "with open(\"t.txt\", \"w\") as f:\n",
    "    f.write(z.as_hlo_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"t.dot\", \"w\") as f:\n",
    "    f.write(z.as_hlo_dot_graph())\n",
    "! dot t.dot  -Tpng > t.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
